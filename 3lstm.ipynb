{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('/Users/sachita/Documents/Projects/Summer/Winter2018/firedata/lstm.csv', sep=',',)\n",
    "\n",
    "timesteps = 12 #timesteps needed later\n",
    "\n",
    "df_shape = final_df.shape #Shape of dataframe before conversion to LSTM format\n",
    "final_cols = final_df.columns.values.tolist() #Titles of columns in dataframe finally\n",
    "n_vars = len(final_cols) #Number of variables we have for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE HOT ENCODING OF Y (for input to lstm)\n",
    "\n",
    "x = final_df.iloc[:, :-1].values\n",
    "y = final_df.iloc[:, -1].values\n",
    "print('Check on current dimensions of x and y: ', x.shape, y.shape) #Just a check on the dimension\n",
    "\n",
    "y = y.astype(int) #type casting for one hot encoding\n",
    "total_classes = len(range(0, 25)) #num of actual classes\n",
    "\n",
    "y_enc = to_categorical(y, num_classes=total_classes)\n",
    "y_enc = y_enc.astype(int)\n",
    "\n",
    "print('Check on final dimensions of x and y: ', x.shape, y_enc.shape) #Just a check on the dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN-TEST SPLIT \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_enc, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print('Shapes of x_train, y_train, x_test and y_test, before reshaping: ', x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features] as expected by LSTM\n",
    "x_train = x_train.reshape((x_train.shape[0], 12, 20))\n",
    "x_test = x_test.reshape((x_test.shape[0], 12, 20))\n",
    "print('Shapes of x_train, y_train, x_test and y_test, after reshaping: ', x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM METRIC\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NEURAL NETWORK - REWRITE IN TENSORFLOW\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_vars, input_shape=(x_train.shape[1], x_train.shape[2]), kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "print(\"Fitting begins.\")\n",
    "# fit network\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32, verbose=1, shuffle=True)\n",
    "\n",
    "# # plot history\n",
    "# pyplot.plot(history.history['loss'], label='train')\n",
    "# pyplot.plot(history.history['val_loss'], label='test')\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss: %.5f\" % (loss))\n",
    "print(\"Accuracy: %.5f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
