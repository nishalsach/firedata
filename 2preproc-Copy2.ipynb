{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/sachita/Documents/Projects/Summer/Winter2018/firedata/fire_mod.csv', sep=',')\n",
    "\n",
    "timesteps = 12 #timesteps needed later\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by lat lon to covert to supervised data\n",
    "df = df.sort_values(['lat', 'lon'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping date for LSTM conversions\n",
    "df = df.drop(['lat', 'lon', 'date', 'gfed'], axis=1)\n",
    "\n",
    "#Naming vital variables\n",
    "df_shape = df.shape #Shape of dataframe before conversion to LSTM format\n",
    "final_cols = df.columns.values.tolist() #Titles of columns in dataframe finally\n",
    "n_vars = len(final_cols) #Number of variables we have for prediction\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array or dataframe.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "            \n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "        \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALISATION OF DATA \n",
    "\n",
    "#Separating x and y to normalise x\n",
    "x_val = df.iloc[:, :-1].values\n",
    "y_val = df.iloc[:, -1].values\n",
    "y_val = np.reshape(y_val, (df_shape[0],1)) #reshaping done to avoid (m,) type shape for y\n",
    "#print(x_val.shape, y_val.shape)\n",
    "\n",
    "#Standard Scaler is used \n",
    "scaler = StandardScaler()\n",
    "scaled_val = scaler.fit_transform(x_val)\n",
    "#print(scaled_val.shape)\n",
    "\n",
    "#concatenate X and Y again\n",
    "final_data = np.concatenate((scaled_val, y_val), axis=1) #returns numpy array\n",
    "print('Shape of dataset, post Normalisation: ', final_data.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION FOR FRAMING AS SUPERVISED LEARNING\n",
    "\n",
    "#generate the column names according to # of features\n",
    "names = list()\n",
    "for i in range(timesteps, 0, -1):\n",
    "    names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "names += ['var20(t)'] #adding last column as the one to be predicted in current timestep\n",
    "# names list now has 253 columns\n",
    "\n",
    "final_df = pd.DataFrame(columns=names)\n",
    "print('Initial shape of empty dataset, without filling/reframing: ', final_df.shape)\n",
    "\n",
    "#devising list of columns to drop from series to supervised function\n",
    "\n",
    "start_index = (timesteps*n_vars)\n",
    "end_index = ((timesteps+1)*n_vars)-1\n",
    "cols_to_drop = list(range(start_index, end_index)) #columns to drop in the series to supervised conversion (2nd last 21 columns)\n",
    "print(start_index, end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALLING FUNCTION TO REFRAME COLUMNS\n",
    "\n",
    "for i in range(3120): #3120 is number of lat-lon pairs\n",
    "    \n",
    "    #timestepping has to be done within a lat-lon pair\n",
    "    reframed = series_to_supervised(final_data[i:(168+i), :], timesteps, 1) #168 because that is the number of entries for each lat lon pair\n",
    "    \n",
    "#     print(\"********\")\n",
    "#     for k in reframed.columns[cols_to_drop]:\n",
    "#         print(k)\n",
    "#     print(\"********\")\n",
    "    \n",
    "    #drop columns we don't want to predict - these are the current weather conditions    \n",
    "    reframed.drop(reframed.columns[cols_to_drop], axis=1, inplace=True)\n",
    "    \n",
    "    #concatenate finally\n",
    "    final_df = pd.concat([final_df, reframed], axis=0)   \n",
    "\n",
    "    #Check on progress\n",
    "    if(i%300==0):\n",
    "        print((i), 'Lat-Lon Pairs Complete')\n",
    "        \n",
    "print('Final Shape of dataset, post reframing: ', final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a final check on the alignment of columns\n",
    "\n",
    "for i in final_df.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to csv to preserve it \n",
    "final_df.to_csv(path_or_buf='/Users/sachita/Documents/Projects/Summer/Winter2018/firedata/lstm.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
